{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup training args/config\n",
    "\n",
    "num_training_steps = 10\n",
    "max_lr = 5e-5\n",
    "min_lr = 5e-6\n",
    "T_max = num_training_steps\n",
    "lora_rank = 64\n",
    "lora_alpha = 128\n",
    "lora_dropout = 0.05\n",
    "\n",
    "\n",
    "\n",
    "# we will later test out for multiple values of this so commented out from here\n",
    "# gradient_accumulation_steps = 8\n",
    "per_device_eval_batch_size = 2\n",
    "eval_accumulation_steps = 8\n",
    "save_total_limit = 3\n",
    "save_steps = 50\n",
    "eval_steps = 10\n",
    "warmup_steps = 10\n",
    "bf16 = True\n",
    "logging_steps = 10\n",
    "weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a lora config\n",
    "from peft import LoraConfig\n",
    "\n",
    "target_modules = [\n",
    "    \"q_proj\",\n",
    "    \"k_proj\",\n",
    "    \"v_proj\",\n",
    "    \"o_proj\",\n",
    "]\n",
    "lora_config = LoraConfig(\n",
    "    r=lora_rank,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=target_modules,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "tokenizer_model = \"meta-llama/Llama-3.2-1B\"\n",
    "original_tokenizer = \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_model)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "original_tokenizer = AutoTokenizer.from_pretrained(original_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use datagen repo to get training data\n",
    "# from /home/ubuntu/datagen/synthetic_sql/interleaved/ds3_cat_abc\n",
    "from datasets import load_from_disk\n",
    "\n",
    "# note we just directly load the train split here\n",
    "ds_path = \"/home/ubuntu/datagen/synthetic_sql/interleaved/ds11_api/train\"\n",
    "\n",
    "ds_train = load_from_disk(ds_path).select(range(500))\n",
    "\n",
    "# the above was tokenized using codellama\n",
    "# detokenize it then retokenize\n",
    "\n",
    "original_bos_token_id = original_tokenizer.bos_token_id\n",
    "original_eos_token_id = original_tokenizer.eos_token_id\n",
    "\n",
    "\n",
    "def retokenize_data(item):\n",
    "    # extract token ids only for the prompt\n",
    "    # use the fact that labels are -100 for original inputs for the \"prompt\" part\n",
    "    original_prompt_ids = [\n",
    "        token_id\n",
    "        for i, token_id in enumerate(item[\"input_ids\"])\n",
    "        if item[\"labels\"][i] == -100\n",
    "        and token_id not in {original_bos_token_id, original_eos_token_id}\n",
    "    ]\n",
    "\n",
    "    original_completion_ids = [\n",
    "        token_id\n",
    "        for i, token_id in enumerate(item[\"input_ids\"])\n",
    "        if item[\"labels\"][i] != -100\n",
    "        and token_id not in {original_bos_token_id, original_eos_token_id}\n",
    "    ]\n",
    "\n",
    "    # now retokenize these with the new tokenizer\n",
    "    new_prompt_encoding = tokenizer(original_tokenizer.decode(original_prompt_ids), add_special_tokens=False)\n",
    "    new_completion_encoding = tokenizer(original_tokenizer.decode(original_completion_ids), add_special_tokens=False)\n",
    "\n",
    "    prompt_ids = new_prompt_encoding[\"input_ids\"]\n",
    "    completion_ids = new_completion_encoding[\"input_ids\"]\n",
    "\n",
    "    input_ids = [tokenizer.bos_token_id] + prompt_ids + completion_ids + [tokenizer.eos_token_id]\n",
    "\n",
    "    labels = [-100] * (len(prompt_ids) + 1) + [x for x in completion_ids] + [tokenizer.eos_token_id]\n",
    "\n",
    "    assert len(input_ids) == len(labels)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": [1] * len(input_ids),\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "\n",
    "ds_train = ds_train.map(retokenize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from peft import get_peft_model\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# data collator function that just pads to the max length of a mini batch\n",
    "def collate_to_max_length(inputs):\n",
    "    # find the max length in input_ids\n",
    "    max_length = len(max(inputs, key=lambda x: len(x[\"input_ids\"]))[\"input_ids\"])\n",
    "    eos = tokenizer.eos_token_id\n",
    "\n",
    "    batch = {\"input_ids\": [], \"attention_mask\": [], \"labels\": []}\n",
    "\n",
    "    for input in inputs:\n",
    "        length = len(input[\"input_ids\"])\n",
    "\n",
    "        batch[\"input_ids\"].append(input[\"input_ids\"] + [eos] * (max_length - length))\n",
    "        batch[\"labels\"].append(input[\"labels\"] + [-100] * (max_length - length))\n",
    "        batch[\"attention_mask\"].append(\n",
    "            input[\"attention_mask\"] + [1] * (max_length - length)\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": torch.tensor(batch[\"input_ids\"]),\n",
    "        \"labels\": torch.tensor(batch[\"labels\"]),\n",
    "        \"attention_mask\": torch.tensor(batch[\"attention_mask\"]),\n",
    "    }\n",
    "\n",
    "\n",
    "def get_trainer(gradient_accumulation_steps: int, per_device_train_batch_size: int):\n",
    "    \"\"\"\n",
    "    Function that creates training args using given gradient_accumulation_steps.\n",
    "    \"\"\"\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./outputs\",\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        max_steps=num_training_steps,\n",
    "        warmup_steps=0,\n",
    "        fp16=False,\n",
    "        bf16=True,\n",
    "        logging_steps=1,\n",
    "        weight_decay=0.01,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    peft_model = get_peft_model(model, lora_config)\n",
    "\n",
    "    optimizer = AdamW(peft_model.parameters(), lr=max_lr)\n",
    "    # Create scheduler\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=T_max, eta_min=min_lr)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=peft_model,\n",
    "        args=training_args,\n",
    "        train_dataset=ds_train,\n",
    "        optimizers=(optimizer, scheduler),\n",
    "        data_collator=lambda x: collate_to_max_length(x),\n",
    "    )\n",
    "\n",
    "    return trainer, peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect\n",
    "\n",
    "# \"loss_kwargs\" in inspect.signature(peft_model.get_base_model().forward).parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "grad_accum = [8, 4, 2]\n",
    "per_device = [1, 2, 4]\n",
    "losses = {}\n",
    "\n",
    "for p, g in zip(per_device, grad_accum):\n",
    "    print(f\"Training with gradient_accumulation_steps:\", g)\n",
    "    print(f\"Training with per_device_train_batch_size:\", p)\n",
    "    trainer, peft_model = get_trainer(g, p)\n",
    "    trainer.train()\n",
    "    losses[g] = trainer.state.log_history\n",
    "    # need to do to prevent OOM\n",
    "    del peft_model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = {}\n",
    "for g in losses:\n",
    "    l[g] = [x['loss'] for x in losses[g] if 'loss' in x]\n",
    "\n",
    "# plot the above dict in mpl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for g in l:\n",
    "    plt.plot(l[g], label=f\"grad_accum_steps={g}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "\n",
    "def train_model(gradient_accumulation_steps):\n",
    "    trainer = get_trainer(gradient_accumulation_steps=gradient_accumulation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
